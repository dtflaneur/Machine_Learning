{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import csv\n",
    "from sklearn import svm\n",
    "import sklearn.feature_extraction.text\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "import re\n",
    "import string\n",
    "import graphviz\n",
    "import sklearn.datasets\n",
    "\n",
    "plt.ioff()\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Documents: 11314\n"
     ]
    }
   ],
   "source": [
    "text_dataset = sklearn.datasets.fetch_20newsgroups(shuffle=True, remove=('headers', 'footers', 'quotes'))\n",
    "text_data = text_dataset.data\n",
    "print('Number of Documents: {}'.format(len(text_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'I am trying to write an image display program that uses\\nthe MIT shared memory extension.  The shared memory segment\\ngets allocated and attached to the process with no problem.\\nBut the program crashes at the first call to XShmPutImage,\\nwith the following message:\\n\\nX Error of failed request:  BadShmSeg (invalid shared segment parameter)\\n  Major opcode of failed request:  133 (MIT-SHM)\\n  Minor opcode of failed request:  3 (X_ShmPutImage)\\n  Segment id in failed request 0x0\\n  Serial number of failed request:  741\\n  Current serial number in output stream:  742\\n\\nLike I said, I did error checking on all the calls to shmget\\nand shmat that are necessary to create the shared memory\\nsegment, as well as checking XShmAttach.  There are no\\nproblems.\\n\\nIf anybody has had the same problem or has used MIT-SHM without\\nhaving the same problem, please let me know.\\n\\nBy the way, I am running OpenWindows 3.0 on a Sun Sparc2.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_size = 1\n",
    "vect = sklearn.feature_extraction.text.CountVectorizer(ngram_range=(ngram_size, ngram_size), min_df=0.01, max_df=0.9,  stop_words='english')\n",
    "vect.fit(text_data)\n",
    "vocab = vect.get_feature_names()\n",
    "bow = vect.transform(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topics(lda_model, feature_names, n_top_words):\n",
    "    for topic_index, topic in enumerate(lda_model.components_):\n",
    "        words =  \" , \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        topic_desc = \"Topic #{}: {}\".format(topic_index, words)\n",
    "        print(topic_desc)\n",
    "        print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=5.0,\n",
       "             max_doc_update_iter=100, max_iter=20, mean_change_tol=0.001,\n",
       "             n_components=15, n_jobs=1, n_topics=None, perp_tol=0.1,\n",
       "             random_state=0, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_components = 15\n",
    "n_top_words = 25\n",
    "lda = LatentDirichletAllocation(n_components=n_components, max_iter=20,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=5.,\n",
    "                                random_state=0)\n",
    "lda.fit(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics in LDA model:\n",
      "Topic #0: states , american , israel , jews , war , national , air , world , israeli , health , united , press , anti , members , april , medical , force , white , land , washington , house , america , south , action , jewish\n",
      "\n",
      "Topic #1: said , did , didn , time , years , right , went , home , got , came , left , just , ago , told , know , going , took , let , says , started , saw , remember , year , later , say\n",
      "\n",
      "Topic #2: question , true , does , answer , different , problem , point , case , use , simply , used , work , correct , read , argument , non , note , value , questions , water , means , cause , rules , way , time\n",
      "\n",
      "Topic #3: file , windows , use , program , files , software , window , ftp , version , dos , available , code , image , pc , graphics , server , mail , pub , info , application , using , display , thanks , set , format\n",
      "\n",
      "Topic #4: people , mr , state , president , person , day , government , country , books , children , book , rights , women , days , 000 , years , known , new , right , order , area , killed , military , today , death\n",
      "\n",
      "Topic #5: com , information , internet , news , group , computer , faq , message , address , request , posting , email , box , commercial , data , users , read , sci , fbi , send , modem , reference , expect , article , network\n",
      "\n",
      "Topic #6: don , think , just , like , know , people , really , say , make , want , way , ve , good , time , going , things , sure , ll , probably , right , better , believe , doesn , thing , lot\n",
      "\n",
      "Topic #7: like , good , know , thanks , car , ve , does , new , just , mac , need , price , looking , power , don , use , anybody , mail , buy , used , work , help , bike , sale , want\n",
      "\n",
      "Topic #8: space , new , program , data , systems , output , 1993 , nasa , year , research , based , test , available , ca , 100 , high , size , offer , gov , earth , 10 , center , cost , used , development\n",
      "\n",
      "Topic #9: edu , package , cs , list , net , send , uk , phone , contact , subject , university , engine , 800 , soon , week , service , jim , michael , mit , address , number , reply , available , email , box\n",
      "\n",
      "Topic #10: drive , card , disk , problem , bit , scsi , memory , using , video , hard , use , bus , mode , drivers , speed , controller , work , driver , monitor , problems , ram , board , mouse , screen , cards\n",
      "\n",
      "Topic #11: key , law , government , use , gun , public , encryption , chip , security , keys , clipper , used , private , guns , control , legal , court , number , weapons , laws , police , chips , federal , technology , algorithm\n",
      "\n",
      "Topic #12: god , jesus , believe , bible , christian , does , life , church , faith , religion , christians , christ , people , word , evidence , say , truth , man , example , hell , love , religious , christianity , existence , true\n",
      "\n",
      "Topic #13: game , team , year , play , games , season , second , win , hockey , league , players , good , points , player , runs , teams , lost , won , moral , early , child , best , cross , division , baseball\n",
      "\n",
      "Topic #14: 10 , 00 , 16 , 25 , 14 , 15 , 12 , 11 , 20 , 17 , 18 , 13 , 24 , 30 , 50 , 19 , 34 , 21 , 40 , 27 , 22 , 45 , 23 , 26 , 28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Topics in LDA model:\")\n",
    "tf_feature_names = vect.get_feature_names()\n",
    "print_topics(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: 'I have a line on a Ducati 900GTS 1978 model with 17k on the clock.  Runs\n",
      "very well, paint is the bronze/brown/orange faded out, leaks a bit of oil\n",
      "and pops out of 1st with hard accel.  The shop will fix trans and oil \n",
      "leak.  They sold the bike to the 1 and only owner.  They want $3495, and\n",
      "I am thinking more like $3K.  Any opinions out there?  Please email me.\n",
      "Thanks.  It would be a nice stable mate to the Beemer.  Then I'll get\n",
      "a jap bike and call myself Axis Motors!\n",
      "\n",
      "-- \n",
      "-----------------------------------------------------------------------\n",
      "\"Tuba\" (Irwin)      \"I honk therefore I am\"     CompuTrac-Richardson,Tx\n",
      "irwin@cmptrc.lonestar.org    DoD #0826          (R75/6)'\n",
      "\n",
      "Topic Distribution:\n",
      "\n",
      "[(0, 0.0035087719312709448), (1, 0.003508773820594445), (2, 0.0035087761618828495), (3, 0.0035087753019973512), (4, 0.0035087725307880262), (5, 0.0035087760903129359), (6, 0.003508776751601177), (7, 0.80097593994192495), (8, 0.0035087747573197487), (9, 0.0035087746699556275), (10, 0.098398886693454146), (11, 0.0035087733469456408), (12, 0.0035087729834657037), (13, 0.058519882815551261), (14, 0.0035087722029352075)]\n"
     ]
    }
   ],
   "source": [
    "test_document = text_data[10]\n",
    "test_document_bow = vect.transform([test_document])\n",
    "topic_predictions = lda.transform(test_document_bow)[0]\n",
    "print(\"Document: '{}'\\n\".format(test_document))\n",
    "print(\"Topic Distribution:\\n\")\n",
    "print(list(enumerate(topic_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
