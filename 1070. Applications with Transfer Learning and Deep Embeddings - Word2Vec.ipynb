{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications with Transfer Learning and Deep Embeddings - Word2Vec\n",
    "- What is Transfer Learning ?\n",
    "- What are embeddings ?\n",
    "- How are Word2Vec vectors learned ?\n",
    "- What types of relationships do Word2Vec vectors capture ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transfer Learning:**  is the concept of transfering the knowledge by using past model and training it to new dataset. When we have a small dataset but very diffcult problem wherein similar problem was earlier solved with a large dataset of similar distribtion, we can levergae the model learnt on the large dataset to train over the newer dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embeddings:** are those feature representations that are extracted from pre trained networks\n",
    "- Are dense continous vector representation from neural networks that contain pertinent information & exhibit semantic relationships\n",
    "- Can be learned in supervised or unsupervised manner\n",
    "- Often useful as unsupervised data representation scheme (like PCA)\n",
    "- Sometimes also are called as 'thought vectors', 'x vectors', 'feature vectors'..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word2Vec:** is an algorithm to learn Word vectors or word embeddings, learned from unstructured text data using negative-skip sampling algorithm  \n",
    "goal of word2vec is to find words that appear often in same context have similar vectors, words that don't have dissimilar vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import numpy\n",
    "from tqdm import tqdm\n",
    "import gensim # gensim: library allows easy access and use of Word2vec\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Word2Vec Vectors [from](https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM&export=download)\n",
    "\n",
    "### Download analogies data [from](http://download.tensorflow.org/data/questions-words.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector for King to queen analogy will be similar as man to woman vector & likewise. These are the kind of analogies will try to capture.\n",
    "![alt text](https://www.tensorflow.org/images/linear-relationships.png \"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('data/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "[ 1.25976562e-01  2.97851562e-02  8.60595703e-03  1.39648438e-01\n",
      " -2.56347656e-02 -3.61328125e-02  1.11816406e-01 -1.98242188e-01\n",
      "  5.12695312e-02  3.63281250e-01 -2.42187500e-01 -3.02734375e-01\n",
      " -1.77734375e-01 -2.49023438e-02 -1.67968750e-01 -1.69921875e-01\n",
      "  3.46679688e-02  5.21850586e-03  4.63867188e-02  1.28906250e-01\n",
      "  1.36718750e-01  1.12792969e-01  5.95703125e-02  1.36718750e-01\n",
      "  1.01074219e-01 -1.76757812e-01 -2.51953125e-01  5.98144531e-02\n",
      "  3.41796875e-01 -3.11279297e-02  1.04492188e-01  6.17675781e-02\n",
      "  1.24511719e-01  4.00390625e-01 -3.22265625e-01  8.39843750e-02\n",
      "  3.90625000e-02  5.85937500e-03  7.03125000e-02  1.72851562e-01\n",
      "  1.38671875e-01 -2.31445312e-01  2.83203125e-01  1.42578125e-01\n",
      "  3.41796875e-01 -2.39257812e-02 -1.09863281e-01  3.32031250e-02\n",
      " -5.46875000e-02  1.53198242e-02 -1.62109375e-01  1.58203125e-01\n",
      " -2.59765625e-01  2.01416016e-02 -1.63085938e-01  1.35803223e-03\n",
      " -1.44531250e-01 -5.68847656e-02  4.29687500e-02 -2.46582031e-02\n",
      "  1.85546875e-01  4.47265625e-01  9.58251953e-03  1.31835938e-01\n",
      "  9.86328125e-02 -1.85546875e-01 -1.00097656e-01 -1.33789062e-01\n",
      " -1.25000000e-01  2.83203125e-01  1.23046875e-01  5.32226562e-02\n",
      " -1.77734375e-01  8.59375000e-02 -2.18505859e-02  2.05078125e-02\n",
      " -1.39648438e-01  2.51464844e-02  1.38671875e-01 -1.05468750e-01\n",
      "  1.38671875e-01  8.88671875e-02 -7.51953125e-02 -2.13623047e-02\n",
      "  1.72851562e-01  4.63867188e-02 -2.65625000e-01  8.91113281e-03\n",
      "  1.49414062e-01  3.78417969e-02  2.38281250e-01 -1.24511719e-01\n",
      " -2.17773438e-01 -1.81640625e-01  2.97851562e-02  5.71289062e-02\n",
      " -2.89306641e-02  1.24511719e-02  9.66796875e-02 -2.31445312e-01\n",
      "  5.81054688e-02  6.68945312e-02  7.08007812e-02 -3.08593750e-01\n",
      " -2.14843750e-01  1.45507812e-01 -4.27734375e-01 -9.39941406e-03\n",
      "  1.54296875e-01 -7.66601562e-02  2.89062500e-01  2.77343750e-01\n",
      " -4.86373901e-04 -1.36718750e-01  3.24218750e-01 -2.46093750e-01\n",
      " -3.03649902e-03 -2.11914062e-01  1.25000000e-01  2.69531250e-01\n",
      "  2.04101562e-01  8.25195312e-02 -2.01171875e-01 -1.60156250e-01\n",
      " -3.78417969e-02 -1.20117188e-01  1.15234375e-01 -4.10156250e-02\n",
      " -3.95507812e-02 -8.98437500e-02  6.34765625e-03  2.03125000e-01\n",
      "  1.86523438e-01  2.73437500e-01  6.29882812e-02  1.41601562e-01\n",
      " -9.81445312e-02  1.38671875e-01  1.82617188e-01  1.73828125e-01\n",
      "  1.73828125e-01 -2.37304688e-01  1.78710938e-01  6.34765625e-02\n",
      "  2.36328125e-01 -2.08984375e-01  8.74023438e-02 -1.66015625e-01\n",
      " -7.91015625e-02  2.43164062e-01 -8.88671875e-02  1.26953125e-01\n",
      " -2.16796875e-01 -1.73828125e-01 -3.59375000e-01 -8.25195312e-02\n",
      " -6.49414062e-02  5.07812500e-02  1.35742188e-01 -7.47070312e-02\n",
      " -1.64062500e-01  1.15356445e-02  4.45312500e-01 -2.15820312e-01\n",
      " -1.11328125e-01 -1.92382812e-01  1.70898438e-01 -1.25000000e-01\n",
      "  2.65502930e-03  1.92382812e-01 -1.74804688e-01  1.39648438e-01\n",
      "  2.92968750e-01  1.13281250e-01  5.95703125e-02 -6.39648438e-02\n",
      "  9.96093750e-02 -2.72216797e-02  1.96533203e-02  4.27246094e-02\n",
      " -2.46093750e-01  6.39648438e-02 -2.25585938e-01 -1.68945312e-01\n",
      "  2.89916992e-03  8.20312500e-02  3.41796875e-01  4.32128906e-02\n",
      "  1.32812500e-01  1.42578125e-01  7.61718750e-02  5.98144531e-02\n",
      " -1.19140625e-01  2.74658203e-03 -6.29882812e-02 -2.72216797e-02\n",
      " -4.82177734e-03 -8.20312500e-02 -2.49023438e-02 -4.00390625e-01\n",
      " -1.06933594e-01  4.24804688e-02  7.76367188e-02 -1.16699219e-01\n",
      "  7.37304688e-02 -9.22851562e-02  1.07910156e-01  1.58203125e-01\n",
      "  4.24804688e-02  1.26953125e-01  3.61328125e-02  2.67578125e-01\n",
      " -1.01074219e-01 -3.02734375e-01 -5.76171875e-02  5.05371094e-02\n",
      "  5.26428223e-04 -2.07031250e-01 -1.38671875e-01 -8.97216797e-03\n",
      " -2.78320312e-02 -1.41601562e-01  2.07031250e-01 -1.58203125e-01\n",
      "  1.27929688e-01  1.49414062e-01 -2.24609375e-02 -8.44726562e-02\n",
      "  1.22558594e-01  2.15820312e-01 -2.13867188e-01 -3.12500000e-01\n",
      " -3.73046875e-01  4.08935547e-03  1.07421875e-01  1.06933594e-01\n",
      "  7.32421875e-02  8.97216797e-03 -3.88183594e-02 -1.29882812e-01\n",
      "  1.49414062e-01 -2.14843750e-01 -1.83868408e-03  9.91210938e-02\n",
      "  1.57226562e-01 -1.14257812e-01 -2.05078125e-01  9.91210938e-02\n",
      "  3.69140625e-01 -1.97265625e-01  3.54003906e-02  1.09375000e-01\n",
      "  1.31835938e-01  1.66992188e-01  2.35351562e-01  1.04980469e-01\n",
      " -4.96093750e-01 -1.64062500e-01 -1.56250000e-01 -5.22460938e-02\n",
      "  1.03027344e-01  2.43164062e-01 -1.88476562e-01  5.07812500e-02\n",
      " -9.37500000e-02 -6.68945312e-02  2.27050781e-02  7.61718750e-02\n",
      "  2.89062500e-01  3.10546875e-01 -5.37109375e-02  2.28515625e-01\n",
      "  2.51464844e-02  6.78710938e-02 -1.21093750e-01 -2.15820312e-01\n",
      " -2.73437500e-01 -3.07617188e-02 -3.37890625e-01  1.53320312e-01\n",
      "  2.33398438e-01 -2.08007812e-01  3.73046875e-01  8.20312500e-02\n",
      "  2.51953125e-01 -7.61718750e-02 -4.66308594e-02 -2.23388672e-02\n",
      "  2.99072266e-02 -5.93261719e-02 -4.66918945e-03 -2.44140625e-01\n",
      " -2.09960938e-01 -2.87109375e-01 -4.54101562e-02 -1.77734375e-01\n",
      " -2.79296875e-01 -8.59375000e-02  9.13085938e-02  2.51953125e-01]\n"
     ]
    }
   ],
   "source": [
    "king_vector = model['king']\n",
    "print(len(king_vector))\n",
    "print(king_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.19494629 -0.2446289  -0.09539795  0.3461914   0.01635742 -0.08374023\n",
      "  0.23876953 -0.42193604 -0.28955078  0.41699982 -0.3466797  -0.43359375\n",
      "  0.01025391  0.1256485   0.06689453 -0.09790039  0.20507812 -0.10098267\n",
      "  0.08251953  0.32373047  0.4580078   0.24821472 -0.20288086  0.28955078\n",
      "  0.10253906 -0.03857422 -0.48242188 -0.1081543   0.15527344 -0.15270996\n",
      " -0.21386719 -0.20581055  0.10595703  0.63391113 -0.5810547  -0.3017578\n",
      " -0.11279297  0.39648438 -0.09619141  0.03613281  0.21411133 -0.6088867\n",
      "  0.3408203   0.12298584  0.29492188 -0.00195312 -0.03781128  0.16821289\n",
      "  0.15332031  0.24481201 -0.04626465  0.13183594 -0.2626953   0.17150879\n",
      " -0.40771484  0.02772522 -0.41064453 -0.1862793   0.07617188 -0.10406494\n",
      "  0.14550781  0.41992188  0.00299072  0.2758789   0.18359375 -0.39794922\n",
      " -0.07757568  0.12207031 -0.43115234  0.42651367  0.19873047  0.12451172\n",
      " -0.11230469  0.17626953 -0.01159668  0.02636719  0.0045166   0.12103271\n",
      "  0.25024414 -0.10375977 -0.22241211  0.20141602  0.07495117  0.09777832\n",
      "  0.33374023  0.09814453 -0.25585938  0.1706543   0.2763672   0.19750977\n",
      "  0.71972656 -0.33666992 -0.31237793 -0.19604492  0.10693359  0.13174438\n",
      "  0.18054199 -0.11962891  0.18017578 -0.07363892  0.15930176  0.06005859\n",
      "  0.09033203 -0.4345703  -0.8984375   0.38330078 -1.2109375  -0.08891869\n",
      "  0.09545898 -0.06201172  0.49536133  0.37646484  0.13684273  0.02380371\n",
      "  0.5290375  -0.2911377   0.24842834 -0.46166992  0.28970337  0.25976562\n",
      "  0.2421875  -0.01977539  0.05554199 -0.30078125  0.32739258 -0.03179932\n",
      "  0.00317383  0.13049316 -0.18139648 -0.01977539  0.1665039   0.6689453\n",
      "  0.2849121   0.7918091   0.17456055  0.3703003  -0.296875    0.14477539\n",
      "  0.4326172  -0.11181641  0.         -0.55566406  0.0949707  -0.18017578\n",
      "  0.45263672 -0.35424805  0.18621063  0.078125   -0.08984375  0.1776123\n",
      " -0.20727539  0.4658203  -0.03369141 -0.35888672 -0.61499023 -0.50146484\n",
      " -0.14404297  0.06420898  0.203125    0.07177734 -0.04443359  0.17779541\n",
      "  0.671875   -0.20980835 -0.10693359 -0.11376953  0.04785156 -0.36035156\n",
      " -0.12527466  0.45581055 -0.3852539   0.2265625   0.75097656  0.33666992\n",
      "  0.04101562 -0.24145508  0.05441284  0.01965332  0.15539551  0.20672607\n",
      " -0.5917969   0.26782227 -0.3260498  -0.09130859  0.36813354 -0.03271484\n",
      "  0.46044922 -0.15942383 -0.05175781  0.5161133   0.03143311 -0.14526367\n",
      " -0.22912598 -0.1359253   0.04772949  0.23498535  0.253479    0.09130859\n",
      " -0.00244141 -0.6455078  -0.01029968  0.04199219  0.1784668  -0.16748047\n",
      "  0.14709473 -0.08544922  0.09863281  0.3203125   0.16235352  0.69433594\n",
      "  0.16601562  0.4189453  -0.20898438 -0.60961914  0.29589844  0.18893433\n",
      " -0.06026459 -0.5415039   0.3154297  -0.0524292  -0.02124023  0.08911133\n",
      "  0.27929688 -0.08407593 -0.03991699  0.14732361 -0.13769531 -0.27539062\n",
      "  0.34960938  0.5390625  -0.53222656 -0.38671875 -0.7158203  -0.07012939\n",
      "  0.58154297  0.0534668   0.18041992 -0.05344391 -0.07360077 -0.27856445\n",
      "  0.2705078  -0.45715332  0.33312225  0.18591309  0.2952881  -0.11993408\n",
      " -0.33935547  0.18798828  0.4724121  -0.38793945 -0.05688477  0.05825806\n",
      "  0.37597656  0.2446289   0.22070312  0.07128906 -0.76660156 -0.17041016\n",
      " -0.3251953  -0.10241699  0.09667969  0.69140625 -0.4482422   0.09375\n",
      " -0.30639648 -0.21826172  0.09838867  0.3125      0.7363281   0.6699219\n",
      " -0.19726562  0.45031738  0.17822266  0.23828125  0.05743408 -0.7109375\n",
      " -0.22753906  0.07177734 -0.2919922   0.46923828  0.23339844 -0.17578125\n",
      "  0.5415039  -0.30444336  0.5500488  -0.26391602 -0.06567383 -0.0135498\n",
      " -0.04788208 -0.0534668  -0.16455078 -0.43847656 -0.38671875 -0.5341797\n",
      " -0.02734375 -0.1550293  -0.02783203  0.16992188  0.33447266  0.3852539 ]\n"
     ]
    }
   ],
   "source": [
    "analogy_vector = model['king'] - model['man'] + model['queen'] # this should give us the vector for gender\n",
    "print(analogy_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king - man + woman = [('queen', 0.7118192911148071), ('monarch', 0.6189674139022827), ('princess', 0.5902431607246399), ('crown_prince', 0.5499460697174072), ('prince', 0.5377321243286133), ('kings', 0.5236844420433044), ('Queen_Consort', 0.5235945582389832), ('queens', 0.5181134343147278), ('sultan', 0.5098593235015869), ('monarchy', 0.5087411999702454)]\n"
     ]
    }
   ],
   "source": [
    "# example analogy task like king - man + woman = queen\n",
    "# gensim library would do the arithmetic i.e. + & - & also will lookup \n",
    "# for the closest vector similar to the calculated vector\n",
    "answer = model.most_similar(positive=['woman', 'king'], negative=['man'])\n",
    "print(\"king - man + woman = {}\".format(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that 'queen' is the top answer in the list of probable matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets apply the same to our list of anologies\n",
    "# we will input the first 3 words and 4th word would be the output\n",
    "analogy_words = [line.rstrip('\\n').split(' ') for line in open('data/questions-words.txt')]\n",
    "analogy_words = [words for words in analogy_words if len(words) == 4]\n",
    "np.random.seed(0)\n",
    "analogy_words = random.sample(analogy_words, 100)\n",
    "X = [words[:3] for words in analogy_words]\n",
    "y = [words[3] for words in analogy_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['listen', 'listening', 'vanish'] vanishing\n",
      "['Ankara', 'Turkey', 'Budapest'] Hungary\n",
      "['Paris', 'France', 'Tokyo'] Japan\n"
     ]
    }
   ],
   "source": [
    "print(X[0], y[0])\n",
    "print(X[10], y[10])\n",
    "print(X[50], y[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:23<00:00,  4.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# Now we run the same on whole dataset\n",
    "is_correct_list = []\n",
    "top_5_predictions_list = []\n",
    "for i in tqdm(range(len(X))):\n",
    "    components = X[i]\n",
    "    answer = y[i]\n",
    "    predictions = model.most_similar(positive=[components[1], components[2]], negative=[components[0]])\n",
    "    top_5_predictions = [p[0].lower() for p in sorted(predictions, key=lambda x : -x[1])[:10]]\n",
    "    top_5_predictions_list.append(top_5_predictions)\n",
    "    is_in_top_5 = 1.0 if answer.lower() in top_5_predictions else 0.0\n",
    "    is_correct_list.append(is_in_top_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Components: ['listen', 'listening', 'vanish'], Answer: vanishing Top5: ['disappear', 'disappearing', 'vanishing', 'evaporate', 'vanished', 'fading', 'fade', 'vanishes', 'disappeared', 'disappears'] is_correct: 1.0\n",
      "Components: ['monkey', 'monkeys', 'hand'], Answer: hands Top5: ['hands', 'hand', 'hands', 'fingers', 'rifle_muzzles', 'sten_guns', 'firmly_clasped', 'forefinger', 'stephen_mcfarren', 'finger'] is_correct: 1.0\n",
      "Components: ['pear', 'pears', 'hand'], Answer: hands Top5: ['hands', 'hands', 'fingers', 'hand', 'fingertips', 'firmly_clasped', 'rifle_muzzles', 'side', 'absolutely_lifeless_hermanstorfer', 'finger'] is_correct: 1.0\n",
      "Components: ['wide', 'widest', 'high'], Answer: highest Top5: ['highest', 'lowest', 'low', 'high', 'higher', 'thehighest', 'highest', 'ahigh', 'lower', 'risen_steadily'] is_correct: 1.0\n",
      "Components: ['nephew', 'niece', 'sons'], Answer: daughters Top5: ['daughters', 'granddaughters', 'daughter', 'grandchildren', 'mother', 'sisters', 'grandsons', 'grandaughters', 'wife', 'nieces'] is_correct: 1.0\n",
      "Components: ['Poland', 'Polish', 'Switzerland'], Answer: Swiss Top5: ['swiss', 'austrian', 'german', 'belgian', 'bern_switzerland', 'canton_ticino', 'fribourg', 'canton_aargau', 'swedish', 'zürich'] is_correct: 1.0\n",
      "Components: ['Vienna', 'Austria', 'Banjul'], Answer: Gambia Top5: ['gambia', 'touray', 'gambian', 'brikama', 'sanyang', 'benin_republic', 'alhagie', 'jammeh', 'serrekunda', 'ghana'] is_correct: 1.0\n",
      "Components: ['rapid', 'rapidly', 'possible'], Answer: possibly Top5: ['humanly_possible', 'practicable', 'possibly', 'quickly', 'soon', 'conceivable', 'feasibly', 'as', 'possibility', 'practicably_possible'] is_correct: 1.0\n",
      "Components: ['Santiago', 'Chile', 'Valletta'], Answer: Malta Top5: ['malta', 'vittoriosa', 'floriana', 'birkirkara', 'cyprus', 'marsaxlokk', 'slovenia', 'qormi', 'bulgaria', 'sliema'] is_correct: 1.0\n",
      "Components: ['dancing', 'danced', 'thinking'], Answer: thought Top5: ['thought', 'thinking', 'talked', 'pondered', 'dreaming', 'think', 'envisioning', 'imagining', 'believing', 'wondered'] is_correct: 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    components = X[i]\n",
    "    answer = y[i]\n",
    "    top5 = top_5_predictions_list[i]\n",
    "    correct = is_correct_list[i]\n",
    "    print(\"Components: {}, Answer: {} Top5: {} is_correct: {}\".format(components, answer, top5, correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in Analogy Task is 0.89\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy in Analogy Task is\", np.mean(is_correct_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
